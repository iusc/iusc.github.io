---
layout: post
title:  "NGHIÊN CỨU VỀ Y – SINH – HOÁ ỨNG DỤNG HỌC MÁY (P2)"
date:   2020-01-08 11:15:00 +0700
---

## KỲ 2: XỬ LÝ DỮ LIỆU ĐẦU VÀO CHO MÔ HÌNH
### 1. Khái niệm căn bản
Như các bạn đã biết, để huấn luyện một mô hình, chúng ta cần ít nhất là 3 tập (dataset), bao gồm:
1. Tập Huấn Luyện (Training Set): Dùng để huấn luyện mô hình
2. Tập Giám Sát (Validation Set): Dùng để theo dõi quá trình huấn luyện để lựa chọn điểm dừng.
3. Tập Kiểm Thảo (Test): Dùng để đánh giá kết quả mô hình.

Vậy nếu chức năng của 3 tập rõ ràng như vậy, chúng ta có gì để sai? Trong thực tế, việc phân chia tập Train, Validation, và Test không phải là việc đơn giản vì
1. Test Set phải được để riêng và không được tác động đến quá trình hình luyện.
2. Validation Set phải khái quát hoá được đặc tính của Test Set
3. Training Set không được chứa dữ liệu trùng với hai tập trên

Nếu chúng ta có đủ dữ liệu (data) để chia sẵn thành 3 tập, điều này thật tuyệt vời. Tuy nhiên, ở một số bài toán, dữ liệu của chúng ta không đủ nhiều để có thể chia thành 3 tập rạch ròi nhưng quá trình giám sát là điều không thể loại bỏ để đảm bảo mô hình không bị quá khớp (overfiting). Đó cũng là lý do mà cross-validation ra đời. Để hiểu một cách đơn giản, cross-validation là giải pháp tình huống cho việc bạn không có Validation Set độc lập. Validation Set lúc này sẽ là một phần của Development Set (mình tự quy ước khi nào sử dụng thuật ngữ cross-validation, thì sẽ thay *Training Set* thành *Development Set* để tránh nhầm lẫn)

### 2. Các lỗi thường gặp
#### 2.1. Data của các tập bị trùng nhau
Đây thì đích thị là vấn đề nghiêm trọng rồi, nhưng nó cũng là vấn đề có thể giải quyết một cách đơn giản nhất bằng cách loại bỏ các mẫu trùng.

#### 2.2. Can thiệp sai
Đối với dữ liệu có tỉ lệ phân chia các lớp (class) bị lệch (imbalance), hoặc dữ liệu chưa chuẩn hoá (unstandardized), hoặc dữ liệu thiếu (unimputed), khi chúng ta quyết định can thiệp, các bạn phải nhớ Test Set không được quyền can thiệp vào bất cứ giai đoạn nào của quá trình huấn luyện, kể cả việc xử lý dữ liệu đầu vào.

##### Lỗi sai thường gặp:
1. Trộn Train và Test vào chung rồi tiến hành chuẩn hoá về scale 0-1. Không biết do vô tình hay cố ý mà hiện nay có rất nhiều bài được đăng trên các tập chí uy tín làm vậy. Dĩ nhiên là họ không ngốc, nhưng việc làm này rõ ràng là có ý đồ năng cao chất lượng, kết quả mô hình. 

**Lý do**: Khi bạn trộn Train và Test chung với nhau, bạn sẽ có 1 độ biến thiên dữ liệu mang đặc điểm **CHUNG** giữa cả Training Set và Test Set. Nếu như vậy, Test Set đã can thiệp vào quá chính chuẩn hoá Training Set.

2. Trộn Train và Val vào chung rồi tiến hành chuẩn hoá: Vấn đề này về bản cũng không khác gì vấn đề khi trộn Train và Test, nhưng nghiêm trọng hơn rất nhiều vì nó quyết định điểm dừng của quá trình huấn luyện mô hình. Nếu bạn có Training Set và Validation Set độc lập thì việc này không phải là vấn đề nhưng nếu bạn tiến hành cross-validation, thì chúc mừng bạn, bạn có thể vô tình quên mất việc tập Validation Set đã được xử lý cùng tập Training Set (Training Set và Validation Set đều được tách ra từ Development Set). 

Khi sử dụng K-fold cross-validation (ví dụ: k=5), ta có lần lượt 4 fold được sử dụng làm Training Set  và 1 fold còn lại được sử dụng làm Validation Set. Quá trình này lặp lại 5 lần với lần lượt các fold còn lại, được sử dụng như Validation Set trong suốt quá trình. Tuy nhiên, vì nhiều người thường tiến hành can thiệp để chuẩn hoá, cân bằng, hay điền khuyết dữ liệu thiếu trong Development Set mà quên mất việc Development Set sau đó sẽ được dùng để làm k-fold cross-validation. Điều này dẫn đến overfitting nặng.

### 3. Các lưu ý để tránh các lỗi nêu trên:
1. Nếu bạn có Validation Set riêng, nên lưu ý việc Validation Set cũng phải được đối xử như Test Set. Mọi sự can thiệp vào dữ liệu, chỉ được tác động lên Training Set. Sau đó, bạn sử dụng các hệ số chuẩn hoá của Training Set để lần lượt áp dụng lên cho Validation Set và Test Set (scaling factor/standardized factor).

2. Nếu bạn chỉ có một Development Set duy nhất, bạn nên chia thành k fold trước. Sau đó ứng với từng fold của Validation Set, bạn để riêng ra không can thiệp, và chỉ can thiệp vào 4 fold của Training Set. Sau đó, bạn sử dụng hệ số chuẩn hoá tính toán từ 4 fold của Training Set để áp dụng lên fold ứng với Validation Set. Bạn làm việc này tổng công là k lần, và kết quả của k-fold cross-validation của bạn sẽ kết quả trung bình của một chỉ số nào đó(AUC, PR-AUC, accuracy, …) để lựa chọn làm điểm dừng. Sau khi bạn đã có tham số tối ưu, bạn có thể lấy trọn vẹn Development Set  để huân luyện mô hình. Bạn tiến hành xử lý Development Set và sau đó áp dụng hệ số chuẩn hoá lên Test Set.

Hai vấn đề mình đề cập ở đây là hai vấn đề căn bản mà bạn phải tránh tuyệt đối khi huấn luyện mô hình. Ngoài ra, đối với các mô hình kết hợp (ensemble) và tối ưu tham số cho mô hình này có một chút điều chỉnh, mình xin hẹn dịp sau sẽ nói rõ hơn.

###### Tác giả: NVTH (nvthoang@gmail.com)
